 

HOOMD-blue can compute BVHs on the GPU and use them for MD simulations as well, the focus of another publication [47]. In this work, we do not attempt to use BVHs on the GPU as they are most useful in simulations with large particle size disparity where there is inherently very little parallelism for the GPU implementation to utilize.  

[ScienceDirect](https://pdf.sciencedirectassets.com/271575/1-s2.0-S0010465516X00069/1-s2.0-S001046551630039X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGkaCXVzLWVhc3QtMSJHMEUCIHYiQ5%2FH11nCglC59yppWJbceD0WQbgW%2BQbahsGB5pjwAiEAy8Lz8DS9ORYM3KCV4qGRgDdU%2F7EZwnQ3gaeokisxxLsqvAUIkv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDF9gi2Yd8NzkBlixCyqQBfPAjfNx6MenzaeNRR9SYQB2DswPntQdyuPSH6QxyWWWnTuV5nFM8Ra6m2lZXb7VV%2FxjSv4i3%2BRy0FDGkRWIQosycflSO3ziipGLD%2BuRIeSn%2FWN%2FdFUDbZFnw%2FFTLYlA%2B29qIzDgR1nltl%2B%2BY%2Bk7hSnXS%2FVq46VoOqbH7iEZfGAR6aSui6sJMaYVyX3BoRabkNdRStVeQ51yYosEt8TveAGU%2FeTQtHt1tXDl8WYqL492%2FScDCSx43DKfAW3BDzCRFdliZ4DqRthp9PRcAEgghY%2FEfbQJkiKckTK0nZYXCq8FgBxguOJiEZ0599K75gmcO7QDTdbKIKwqd5Q57fm6%2FcOCN%2FtNwu4N2mw839T24OR0lKyj6bIlePqwst6%2FiroFCY5KHyCZ6%2BIfu5RWsPsLQszhXOrgrt49%2FHgHqh6Nt47WckZe4B%2Bb4LcjeGdgCN%2B6iTZIrTTa0JUrLuBX7amDuwE3ouKprnGXrXiupWBli5bXQ0lRX4No85%2F3WZCbScpvMDHywrnLgV3%2BJOB5Wkt38Eknrdxz55XqMYaj5svyCQxmODVV5hUjrdCmMlgKPU%2Bz3ujMxg1KEid95cUfjZhHL5Qiq5WQAsYJSxiSb5S4Pfu%2BQbmhSkjp1c528EPhW7Cglr1Vs97R1Hz3Z58HlQUQmgfrQ%2BK35o3OC695KOw5rJOhnhDRDZ5%2FDqjSygU3%2BaaDgdDKL2Lg1Hi64yBXKrgxgOF2CEaDM2blJfWJ%2FQqhaq0Knr3i2rGvqAp6UN0u0r96GKCg%2FqJEgwi%2FwzAnWtcfxJ5diCECrGiyUdA%2FY5kIhg1ABjc%2B4Dcy6Xkp3XnGeuLokTyEqFO3JNeMyCCo6hR4HVdxjl%2BKGa8vCUY4fYVEpGObMMP00r0GOrEBHeTeL46NJs%2FqjsM8qLcfG%2BXxGKwrUgR2dR8WoAc0p0vw0ETakXg4LmOVUXuU3AwalV1fCDRS%2BHSSyy02yM1sBlngVpqimKhpGQuyZFxLXBdGbU9NG1XObfgxKoDXGUsaDAU3rHT11I8y63sSLXmskNHnT537tgTk9MA%2FxE%2F2fECjCOSgftZG6o48%2BqLgSXF%2FHvCazuKrscdC6GsgDsIi42IyM0RWx9ghJVHdxoBpiprt&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250218T181954Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY45LNCG6M%2F20250218%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8ba678ef8caabdbad40929d500a30f0ab58bdc51dca75a9cc19858e02a988300&hash=c82034a0b533b256f69d88cae0a4016d750510a5b1361e067fad568eb1aec433&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S001046551630039X&tid=spdf-63cc4a77-4a23-4460-a100-23c52cebf253&sid=e4c46d1927585442a37bba33949666a50378gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=050d5b51515254545254&rr=914007317e3208d9&cc=cn)



![](https://cdn.nlark.com/yuque/0/2025/png/52606999/1739902930010-f74f85da-c557-4013-a93c-73f04fce9221.png)

![](https://cdn.nlark.com/yuque/0/2025/png/52606999/1739902844018-b58436c6-3a90-475d-9de0-260f130dd1a2.png)

<font style="color:rgb(28, 33, 39);">外框为三菱模拟框，分为 4 个域。每个域的右侧和底部边缘都有一个灰色的非活动区域，宽度为一个粒子直径。非活动区域内的粒子颜色较浅，不会被选中进行试验移动。任何在非活动区域结束的试运行配置都必须被剔除（本例中为左上方的域）。在 GPU 上，单个域用棋盘格进一步细分。</font>

 To scale beyond a single compute node, we employ a domain decomposition strategy using MPI with one rank per CPU core, or one rank per GPU. We implement HPMC as an extension of HOOMD-blue, a parallel MD code that already has the necessary decomposition and communications routines [40]. Each rank covers a portion of the simulation box and ownsall of the particles in that region. The communications routines copy particle data from neighboring ranks in a ghost layer around each domain, and migrate particles from one domain to another as they move. 



这段话描述了使用**MPI（消息传递接口）****和****域分解（domain decomposition）****策略来并行化****HPMC（硬粒子Monte Carlo）****模拟的实现方法，具体是在****HOOMD-blue**框架的基础上扩展的。我们可以将这段话分为几个关键部分来解释：

### 1. **并行化和域分解**
+ 为了扩展模拟到多个计算节点或多核/多GPU的系统中，采用了**MPI**的域分解策略。每个**CPU核心或GPU**运行一个**MPI进程**。
+ 每个进程处理模拟盒的一个区域，并且每个进程管理该区域内的粒子。
+ **HOOMD-blue**本身是一个并行的**分子动力学（MD）**模拟代码，已经有了必要的分解和通信机制，因此可以在此基础上实现HPMC。

### 2. **粒子数据通信**
+ 每个进程覆盖模拟盒的部分区域，**相邻进程之间通过幽灵层进行通信**，这些幽灵层复制了邻近进程中的粒子数据。
+ **幽灵层（ghost layer）**的作用是保证每个进程能获取到临近区域的粒子信息，从而进行粒子移动和相互作用计算。
+ 当粒子在模拟中移动时，它们可能会从一个进程的域迁移到另一个进程的域，通信确保数据的准确性和一致性。

### 3. **棋盘格方案与活动/非活动区域**
+ 在低线程数下，使用传统的2D棋盘格方案不再是最佳选择，因为这样每次只更新系统的一部分并且需要频繁进行幽灵层通信，这在效率上可能较低。
+ 该方法改为**将系统划分为活动区域和非活动区域**，并使活动区域尽可能大。非活动区域的宽度为**dmax**，并位于每个域的底部、右侧和后侧。
+ 在这种布局下，**所有非活动粒子都被放置在相邻域的幽灵层内**，或者与相邻域的活动粒子之间隔开。这减少了需要更新的幽灵层的数量，提高了效率。

### 4. **通信和子步骤**
+ 在每个子步骤后，不需要频繁进行幽灵层的通信，因为非活动粒子不移动，它们不需要更新。
+ **进程之间的通信只在步骤结束时进行**，并且在此时，系统会应用一个**随机位移**来处理所有粒子的更新，并迁移粒子到新的域。
+ 用户可以通过设置**ns**（每步执行的子步骤数）来控制计算和通信之间的比例。

### 5. **粒子移动和缓存友好性**
+ 为了实现**详细平衡（detailed balance）**，系统会在**棋盘格方案中随机选择粒子进行试探移动**，并通过正向或反向索引顺序来遍历粒子。
+ 这个方法改进了传统方案中的**缓存抖动问题**。通过调整粒子索引的顺序，能够提高缓存的访问效率，从而加速模拟。
+ 每个粒子在其区域内进行试探性随机移动，然后检查是否与其他粒子发生重叠，如果没有重叠则接受该移动，更新粒子位置和AABB（轴对齐包围盒）树。

### 6. **实现步骤概述**
总结出HPMC模拟的具体操作流程，包括以下步骤：

1. **生成AABB树**，用于检查粒子间的重叠。
2. **随机选择正向或反向索引顺序**，以便缓存优化。
3. **遍历所有粒子**，跳过位于非活动区域的粒子。
4. 为每个粒子生成**随机的试探性移动**，并检查新位置是否在活动区域内。
5. **检查试探移动的重叠情况**，若没有重叠，则接受移动并更新AABB树。
6. **重复试探移动操作ns次**，执行多次试探移动。
7. **应用一个随机位移**并将所有粒子平移。
8. **粒子迁移到新域**，并进行幽灵粒子通信。
9. 这一步骤继续执行直到达到预定的模拟步数。

### 7. **并行化性能和配置**
+ 在单进程运行时，一步执行**ns次扫描**。随着并行进程数量的增加，**活动粒子和非活动粒子的比例会发生变化**，这将影响每步的扫描次数。
+ 用户需要理解这一点并根据计算资源配置正确的运行协议，以确保系统在并行化时能够达到预期的性能。

总的来说，这段话详细描述了如何通过并行化和域分解策略在多个计算节点上高效实现HPMC模拟，优化了粒子移动的计算方式和通信机制，并提供了如何在不同计算配置下调整工作负载的建议。





## findDecomposition
```cpp
//! Find a domain decomposition with given parameters
bool DomainDecomposition::findDecomposition(unsigned int nranks,
                                            const Scalar3 L,
                                            unsigned int& nx,
                                            unsigned int& ny,
                                            unsigned int& nz)
    {
    assert(L.x > 0);
    assert(L.y > 0);

    // Calculate the number of sub-domains in every direction
    // by minimizing the surface area between domains at constant number of domains
    bool is2D = L.z == 0.0;
    double min_surface_area; // surface area in 3D, perimeter length in 2D
    if (is2D)
        {
        min_surface_area = L.x * (double)(nranks - 1);
        }
    else
        {
        min_surface_area = L.x * L.z * (double)(nranks - 1);
        }

    unsigned int nx_in = nx;
    unsigned int ny_in = ny;
    unsigned int nz_in = nz;

    bool found_decomposition = (nx_in == 0 && ny_in == 0 && nz_in == 0);

    // initial guess
    nx = 1;
    if (is2D)
        {
        ny = nranks;
        nz = 1;
        }
    else
        {
        ny = 1;
        nz = nranks;
        }

    for (unsigned int nx_try = 1; nx_try <= nranks; nx_try++)
        {
        if (nx_in != 0 && nx_try != nx_in)
            continue;
        for (unsigned int ny_try = 1; nx_try * ny_try <= nranks; ny_try++)
            {
            if (ny_in != 0 && ny_try != ny_in)
                continue;
            for (unsigned int nz_try = 1; nx_try * ny_try * nz_try <= nranks; nz_try++)
                {
                if (nz_in != 0 && nz_try != nz_in)
                    continue;
                if (nx_try * ny_try * nz_try != nranks)
                    continue;
                if (is2D && nz_try > 1)
                    continue;
                double surface_area;
                if (is2D)
                    {
                    surface_area = L.x * (ny_try - 1) + L.y * (nx_try - 1);
                    }
                else
                    {
                    surface_area = L.x * L.y * (double)(nz_try - 1)
                                   + L.x * L.z * (double)(ny_try - 1)
                                   + L.y * L.z * (double)(nx_try - 1);
                    }
                if (surface_area < min_surface_area || !found_decomposition)
                    {
                    nx = nx_try;
                    ny = ny_try;
                    nz = nz_try;
                    min_surface_area = surface_area;
                    found_decomposition = true;
                    }
                }
            }
        }

    return found_decomposition;
    }
```





